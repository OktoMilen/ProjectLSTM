# 1. Load Packages/Library

```{r}
library(tensorflow)
library(keras)
library(readxl)
library(dplyr)
library (ggplot2)
library (caTools)
library(lubridate)
library(caret)
library(tibble)
```


# 2. Obtain Data
```{r}
dataset<- read.csv("Data/dataspku.csv")
View(dataset)
```

## 2.1 Menghapus Variabel yang tidak diperlukan.
```{r}
dataset=dataset[,-1]
```


# 3. Scrub Data
## a. Melihat Summary data
```{r}
summary(dataset)
```



## b. Mengubah Tipe Data Variabel PM10, so2, co, o3, no2
```{r}
dataset$pm10<-as.numeric(dataset$pm10)
dataset$so2<-as.numeric(dataset$so2)
dataset$co<-as.numeric(dataset$co)
dataset$o3<-as.numeric(dataset$o3)
dataset$no2<-as.numeric(dataset$no2)
```
Pada bagian ini dilakukan sebuah pengubahan tipe data variabel yang semula bertipe character diubah menjadi numeric



## C. Mengubah tipe Data Variabel Tanggal
```{r}
datasetclean<-datasetclean%>%
  mutate(Tanggal=ymd(Tanggal))%>%
  arrange(Tanggal)
```

Pada bagian ini dilakukan sebuah pengubahan tipe data variabel Tanggal yang semula bertipe character diubah menjadi Date


## D. Memeriksa data yang bersifat Missing Value
```{r}
colSums(is.na(dataset))
```
Dapat kita lihat pada bagian ini jumlah data yang bersifat missing value pada masing masing variabel


## E. Membersihkan Data yang bersifat Missing Value
```{r}
datasetclean<-na.omit(dataset)
```

```{r}
colSums(is.na(datasetclean))
```
Dapat kita lihat, sudah tidak ada data yang bersifat missing value pada masing masing variabel


# 4. Explore Data
## a. Analisis Deskriptif

```{r}
summary(datasetclean)
```

```{r}
sd(datasetclean$pm10)
sd(datasetclean$so2)
sd(datasetclean$co)
sd(datasetclean$o3)
sd(datasetclean$no2)
```
Pada bagian ini dapat kita lihat hasil Standar Deviasi dari variabel pm10, so2, co, o3, no2



## b. Visualisasi Data
### b.1 Grouping Jumlah pada setiap partikulat
```{r}
pm10v<-datasetclean%>%
  mutate(first_date_month=floor_date(Tanggal,unit="month"))%>%
  group_by(first_date_month)%>%
  summarise(jumlahPM10=sum(pm10))

so2v<-datasetclean%>%
  mutate(first_date_month=floor_date(Tanggal,unit="month"))%>%
  group_by(first_date_month)%>%
  summarise(jumlahSO2=sum(so2))

cov<-datasetclean%>%
  mutate(first_date_month=floor_date(Tanggal,unit="month"))%>%
  group_by(first_date_month)%>%
  summarise(jumlahCO=sum(co))

o3v<-datasetclean%>%
  mutate(first_date_month=floor_date(Tanggal,unit="month"))%>%
  group_by(first_date_month)%>%
  summarise(jumlahO3=sum(o3))

no2v<-datasetclean%>%
  mutate(first_date_month=floor_date(Tanggal,unit="month"))%>%
  group_by(first_date_month)%>%
  summarise(jumlahNO2=sum(no2))
```

### b.1.1 Visualisasi Data Jumlah partikulat polusi udara per bulan
```{r}
ggplot(data=pm10v,aes(x=first_date_month,y=jumlahPM10,color="PM10"))+
  geom_line()+
  geom_line(data = so2v,aes(x=first_date_month,y=jumlahSO2,color="SO2"))+
  geom_line(data = cov,aes(x=first_date_month,y=jumlahCO,color="CO"))+
  geom_line(data = o3v,aes(x=first_date_month,y=jumlahO3,color="O3"))+
  geom_line(data = no2v,aes(x=first_date_month,y=jumlahNO2,color="NO2"))+
  labs(title = "Jumlah Partikel Polusi Udara Per Bulan",
       x="Tahun",
       y="Jumlah Partikel (ug/m3",
       subtitle = "Data terakhir 31 Desember 2021")+
  theme_minimal()+
  scale_x_date(date_labels = "%Y",date_breaks = "1 year")+
  scale_color_manual(values = c("#aa6200","#dd9533","#33dd95","#4033dd","#d0dd33"),
                     labels=c("PM10","SO2","CO","O3","NO2"))+
  theme(legend.position = "top")
```


### b.2 Visualisasi Data Partikulat Polusi Udara PM10
```{r}
datasetclean %>% 
  select(pm10,Tanggal) %>%
  ggplot(aes(x = Tanggal,y=pm10)) +
  geom_line(aes(col = pm10)) +
  labs(title = "Tingkat Partikulat PM10",
       x = "Tahun",
       y = "Nilai PM10") +
  theme_minimal()
```

### b.3 Visualisasi Data SO2
```{r}
datasetclean %>% 
  select(so2,Tanggal) %>%
  ggplot(aes(x = Tanggal,y=so2)) +
  geom_line(aes(col = so2)) +
  labs(title = "Tingkat Sulfur Dioksida",
       x = "Tahun",
       y = "Nilai SO2") +
  theme_minimal()
```


### b.4 Visualisasi Data CO
```{r}
datasetclean %>% 
  select(co,Tanggal) %>%
  ggplot(aes(x = Tanggal,y=co)) +
  geom_line(aes(col = co)) +
  labs(title = "Tingkat Karbon Monoksida",
       x = "Tahun",
       y = "Nilai CO") +
  theme_minimal()
```



### b.5 Visualisasi Data O3
```{r}
datasetclean %>% 
  select(o3,Tanggal) %>%
  ggplot(aes(x = Tanggal,y=o3)) +
  geom_line(aes(col = o3)) +
  labs(title = "Tingkat Ozon",
       x = "Tahun",
       y = "Nilai O3") +
  theme_minimal()
```

### b.6 Visualisasi Data no2
```{r}
datasetclean %>% 
  select(no2,Tanggal) %>%
  ggplot(aes(x = Tanggal,y=no2)) +
  geom_line(aes(col = no2)) +
  labs(title = "Tingkat Nitrogen Dioksida",
       x = "Tahun",
       y = "Nilai NO2") +
  theme_minimal()
```


### b.7 Visualisasi Data PM10 berdasarkan salah satu Stasiun
```{r}
datasetclean %>% 
  filter(Stasiun==("DKI1 (Bunderan HI)"))%>%
  select(pm10,Stasiun,Tanggal) %>%
  ggplot(aes(x = Tanggal,y=pm10))+
  geom_line(aes(col = Stasiun)) +
  labs(title = "Tingkat Partikulat PM10 Pada stasiun DKI1 (Bunderan HI)",
       x = "Tahun",
       y = "Nilai PM10") +
  theme_minimal()
```

# 5. Model
Definisikan model prediksi yang akan dilakukan berdasarkan metode yg digunakan LSTM.

## a. Pembagian Dataset
```{r}
split=sample.split(datasetclean,SplitRatio = 0.7)
training_set=subset(datasetclean,split==TRUE)
test_set=subset(datasetclean,split==FALSE)
```


```{r}
model <- keras_model_sequential() %>%
  layer_lstm(units = 64, input_shape = c(240, 1)) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dense(units = 8, activation = "relu") %>%
  layer_dense(units = 1, activation = "relu") 
summary(model)
```

```{r}
model %>% compile(optimizer = "rmsprop",
         loss = "binary_crossentropy",
         metrics = c("acc"))
```


```{r}
history <-
  model %>% fit (
    training_set,
    test_set,
    batch_size = 100,
    epochs = 5,
    validation_split = 0.1,
    use_multiprocessing = T
  )
```